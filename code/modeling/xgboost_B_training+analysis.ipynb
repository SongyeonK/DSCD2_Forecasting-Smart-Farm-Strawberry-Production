{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type B XGBoost 모델 학습 + 결과 시각화 + SHAP 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/DS/캡스톤디자인 II/xai/최최종데이터_b_지난주추가.csv\", encoding = \"cp949\")\n",
    "df = df.drop(columns=['week_start_date'])\n",
    "\n",
    "columns = ['flw_get','last_flw_get','height_pl','num_leaf','len_leaf','width_leaf','unit_len','dim_pipe',\n",
    "           'temp_ex_day','temp_ex_night','sr_ex_day','temp_int_day','temp_int_night','hum_int_day','hum_int_night',\n",
    "           'CO2_day','CO2_night','soil_temp_day','soil_temp_night']\n",
    "\n",
    "# RobustScaler object\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Scale selected columns\n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "\n",
    "# Separate independent and dependent variables\n",
    "X = df.drop(columns=['flw_get'])  # Independent variables\n",
    "y = df['flw_get']  # Dependent variable\n",
    "\n",
    "# Group data by week\n",
    "week_groups = df.groupby('week')\n",
    "\n",
    "# Select data for training from week 4 to week 25\n",
    "train_weeks = list(range(5, 26))\n",
    "train_data = pd.concat([group for week, group in week_groups if week in train_weeks])\n",
    "\n",
    "# Select data for testing from week 26 to week 30\n",
    "test_weeks = list(range(26, 31))\n",
    "test_data = pd.concat([group for week, group in week_groups if week in test_weeks])\n",
    "\n",
    "# Separate independent and dependent variables for training and testing\n",
    "X_train = train_data.drop(columns=['flw_get', 'id', 'week', 'obj_num'])  # Independent variables\n",
    "y_train = train_data['flw_get']  # Dependent variable\n",
    "X_test = test_data.drop(columns=['flw_get', 'id', 'week', 'obj_num'])  # Independent variables\n",
    "y_test = test_data['flw_get']  # Dependent variable\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                                 colsample_bytree=1, max_depth=7)\n",
    "# print(len(X_train), len(X_test))\n",
    "\n",
    "xgb_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 그리드 설정 >> 새로 지정해준 값들\n",
    "param_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [6],\n",
    "    'learning_rate': [0.03],\n",
    "    'subsample': [0.8],\n",
    "    'gamma': [0.01],\n",
    "    'min_child_weight': [5]\n",
    "}\n",
    "\n",
    "# GridSearchCV 생성\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgboost.XGBRegressor(random_state=100, n_jobs=-1),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# 그리드 서치를 사용하여 최적의 모델 훈련\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 최적의 모델 얻기\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 최적의 모델로 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 최적의 모델로 평가 지표 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE (Best Model): {mse}\")\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(range(len(y_test)), y_test, color='blue', label='Actual')\n",
    "plt.plot(range(len(y_pred)), y_pred, color='red', label='Predicted')\n",
    "for i in range(1, 11):\n",
    "    plt.axvline(x=20*i, linestyle='dotted', color='gray')\n",
    "plt.title(\"Actual vs. Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "!pip install shap\n",
    "\n",
    "import shap\n",
    "\n",
    "# shap_values 계산을 위한 masker 생성\n",
    "masker = shap.maskers.Independent(data=X_train.values)\n",
    "\n",
    "# shap.Explainer에 masker 전달\n",
    "explainer = shap.Explainer(xgb_model, masker)\n",
    "\n",
    "# shap_values 계산\n",
    "shap_values = explainer.shap_values(X_test.values)\n",
    "\n",
    "for selected_feature_name in X_test.columns :\n",
    "  # 선택한 특성의 이름\n",
    "  selected_feature_index = X_test.columns.get_loc(selected_feature_name)\n",
    "\n",
    "  # RobustScaler의 중앙값과 IQR 이용\n",
    "  center = scaler.center_[df.columns.get_loc(selected_feature_name)-4]\n",
    "  scale = scaler.scale_[df.columns.get_loc(selected_feature_name)-4]\n",
    "\n",
    "  # 스케일링된 데이터를 원래 값으로 역변환\n",
    "  feature_values_original = X_test[selected_feature_name].values * scale + center\n",
    "\n",
    "  # dependence plot 그리기\n",
    "  plt.figure(figsize=(10, 6))\n",
    "\n",
    "  plt.scatter(feature_values_original, shap_values[:, selected_feature_index], c=y_test)\n",
    "  plt.xlabel(selected_feature_name)\n",
    "  plt.ylabel('SHAP Value')\n",
    "  plt.title(f'XGBoost A with SHAP - Dependence Plot for {selected_feature_name}')\n",
    "  plt.colorbar(label='Actual Target Value')\n",
    "  plt.savefig(f\"{selected_feature_name}_dependence_plot_original.png\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "# 트리 시각화\n",
    "rcParams['figure.figsize'] = 100, 200\n",
    "plot_tree(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot\n",
    "import shap\n",
    "\n",
    "# 모델 설명자 생성\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "\n",
    "# SHAP 값 계산\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 특성 중요도 시각화\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "--------------------------------------------------------------------\n",
    "import shap\n",
    "\n",
    "# 모델 설명자 생성\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "\n",
    "# SHAP 값 계산\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.plots.bar(shap_values)\n",
    "--------------------------------------------------------------------\n",
    "# interaction plot\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "shap.summary_plot(shap_interaction_values, X_train)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
