{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type B GRU 모델 학습 + SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap\n",
    "\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"최최종데이터_b_지난주추가.csv\")\n",
    "df.sort_values(by=[\"id\", \"week\", \"obj_num\"], inplace=True)\n",
    "columns = df.columns[4:]\n",
    "\n",
    "# 데이터 스케일링\n",
    "scaler = RobustScaler()\n",
    "df[columns] = scaler.fit_transform(df[columns])\n",
    "\n",
    "# 독립 변수와 종속 변수 분리\n",
    "X = df.drop(columns=['flw_get'])\n",
    "y = df['flw_get']\n",
    "\n",
    "# 주차(week) 정보를 기준으로 데이터를 그룹화\n",
    "week_groups = df.groupby('week')\n",
    "\n",
    "# 5주차부터 25주차까지를 훈련 데이터로 선택\n",
    "train_weeks = list(range(5, 26))\n",
    "train_data = pd.concat([group for week, group in week_groups if week in train_weeks])\n",
    "\n",
    "# 26주차부터 30주차까지를 테스트 데이터로 선택\n",
    "test_weeks = list(range(26, 31))\n",
    "test_data = pd.concat([group for week, group in week_groups if week in test_weeks])# 주차(week) 정보를 기준으로 데이터를 그룹화\n",
    "\n",
    "# 독립 변수와 종속 변수 분리\n",
    "X_train = train_data.drop(columns=['flw_get', 'id', 'week', 'obj_num', 'week_start_date'])  # 독립 변수 (week_start_date 열 제거)\n",
    "y_train = train_data['flw_get']  # 종속 변수\n",
    "X_test = test_data.drop(columns=['flw_get', 'id', 'week', 'obj_num', 'week_start_date'])  # 독립 변수 (week_start_date 열 제거)\n",
    "y_test = test_data['flw_get']  # 종속 변수\n",
    "\n",
    "# GRU 모델 학습\n",
    "def gru(X_train, y_train, num_units=75, num_layers=2, learning_rate=0.00005, epochs=200, batch_size=32):\n",
    "    models = []\n",
    "    model = Sequential()\n",
    "    model.add(GRU(num_units, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(GRU(num_units, return_sequences=True))\n",
    "    model.add(GRU(num_units))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증\n",
    "def validation(X_test, y_test, models, title) :\n",
    "\n",
    "  validation_results_mse = []\n",
    "  validation_results_rmse = []\n",
    "\n",
    "  for model in models:\n",
    "      y_pred = model.predict(X_test)\n",
    "      mse = mean_squared_error(y_test, y_pred)\n",
    "      rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "      validation_results_mse.append(mse)\n",
    "      validation_results_rmse.append(rmse)\n",
    "\n",
    "  # 검증 결과 평균 출력\n",
    "  mean_mse = np.mean(validation_results_mse)\n",
    "  print(\"평균 검증 MSE:\", mean_mse)\n",
    "\n",
    "  mean_rmse = np.mean(validation_results_rmse)\n",
    "  print(\"평균 검증 RMSE:\", mean_rmse)\n",
    "\n",
    "\tplt.figure(figsize=(15,10))\n",
    "\n",
    "  plt.plot(range(len(y_test)), y_test, color='blue')\n",
    "  plt.plot(range(len(y_pred)), y_pred,  color='red')\n",
    "\n",
    "  for i in range(1, 11) :\n",
    "    plt.axvline(x=20*i, linestyle='dotted')\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.savefig(f\"{title}.png\")\n",
    "  plt.show()\n",
    "  return mean_mse, mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝할 하이퍼파라미터 후보 정의\n",
    "num_units_case = [75]\n",
    "num_layers_case = [3]\n",
    "learning_rate_case = [0.001]\n",
    "epochs_case = [200]\n",
    "batch_size_case = [16]\n",
    "\n",
    "# 그리드 서치 수행\n",
    "history = {\"case\": [], \"model\": [],\n",
    "           \"num_units\": [], \"num_layers\": [], \"learning_rate\": [], \"epochs\": [], \"batch_size\": [],\n",
    "           \"mean_mse\": [], \"mean_rmse\": []}\n",
    "\n",
    "case_ = \"B\"\n",
    "model_ = \"GRU\"\n",
    "\n",
    "for num_units in num_units_case:\n",
    "  for num_layers in num_layers_case:\n",
    "    for learning_rate in learning_rate_case:\n",
    "      for epochs in epochs_case:\n",
    "        for batch_size in batch_size_case:\n",
    "          # 파일 저장용 제목\n",
    "          title = f\"{case_}_{model_}({num_units}_{num_layers}_{learning_rate}_{epochs}_{batch_size})\"\n",
    "          print(f\"{title}\")\n",
    "\n",
    "          # 모델 학습\n",
    "          models = gru(X_train, y_train,\n",
    "                      num_units=num_units,\n",
    "                      num_layers=num_layers,\n",
    "                      learning_rate=learning_rate,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size)\n",
    "\n",
    "          # SHAP을 사용한 모델 해석 및 검증\n",
    "          models_with_shap = gru_with_shap(X_train, y_train,\n",
    "                                              X_test,\n",
    "                                              num_units=num_units,\n",
    "                                              num_layers=num_layers,\n",
    "                                              learning_rate=learning_rate,\n",
    "                                              epochs=epochs,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "          # 검증 진행\n",
    "          mean_mse, mean_rmse = validation(X_test, y_test, models_with_shap, title)\n",
    "\n",
    "          # 기록\n",
    "          history[\"case\"].append(case_)\n",
    "          history[\"model\"].append(model_)\n",
    "          history[\"num_units\"].append(num_units)\n",
    "          history[\"num_layers\"].append(num_layers)\n",
    "          history[\"learning_rate\"].append(learning_rate)\n",
    "          history[\"epochs\"].append(epochs)\n",
    "          history[\"batch_size\"].append(batch_size)\n",
    "          history[\"mean_mse\"].append(mean_mse)\n",
    "          history[\"mean_rmse\"].append(mean_rmse)\n",
    "\n",
    "# 기록 저장\n",
    "history_df = pd.DataFrame.from_dict(data=history, orient='columns')\n",
    "history_df.to_csv(f\"history_{case_}_{model_}.csv\", index=False)\n",
    "\n",
    "# 전체 파일 저장용\n",
    "import os\n",
    "\n",
    "file_list = os.listdir(\"/content\")\n",
    "file_list\n",
    "\n",
    "for i in file_list:\n",
    "    if i == '.config' or i == 'sample_data':\n",
    "        continue\n",
    "    else:\n",
    "        files.download(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP을 사용한 GRU 모델 해석\n",
    "def gru_with_shap(X_train, y_train, X_test, num_units=75, num_layers=2, learning_rate=0.00005, epochs=200, batch_size=32):\n",
    "    X_train_np = X_train.values\n",
    "    y_train_np = y_train.values\n",
    "    X_test_np = X_test.values\n",
    "\n",
    "    models = []\n",
    "    model = Sequential()\n",
    "    model.add(GRU(num_units, input_shape=(X_train_np.shape[1], 1), return_sequences=True))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(GRU(num_units, return_sequences=True))\n",
    "    model.add(GRU(num_units))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mean_squared_error')\n",
    "    model.fit(X_train_np, y_train_np, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    models.append(model)\n",
    "\n",
    "    # shap_values 계산을 위한 masker 생성\n",
    "    masker = shap.maskers.Independent(data=X_train_np)\n",
    "\n",
    "    # shap.Explainer에 masker 전달\n",
    "    explainer = shap.Explainer(model, masker)\n",
    "\n",
    "    # shap_values 계산\n",
    "    shap_values = explainer.shap_values(X_test_np)\n",
    "\n",
    "\n",
    "    # SHAP summary plot 그리기\n",
    "    shap.summary_plot(shap_values, features=X_test_np, feature_names=X_test.columns, show=False)\n",
    "    plt.title(\"GRU B with SHAP - Summary Plot\")\n",
    "    plt.savefig(\"gru_B_shap_summary_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # # SHAP bar plot 그리기\n",
    "    shap.summary_plot(shap_values, features=X_test_np, feature_names=X_test.columns, plot_type='bar', show=False)\n",
    "    plt.subplots_adjust(top=0.9, bottom=0.1, left=0.1, right=0.9)\n",
    "    plt.title(\"GRU B with SHAP - Bar Plot\")\n",
    "    plt.savefig(\"gru_B_shap_bar_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # index 시작 확인하기\n",
    "    for selected_feature_name in X_test.columns:\n",
    "      print(selected_feature_name)\n",
    "      print(df.columns.get_loc(selected_feature_name))\n",
    "\n",
    "\n",
    "    # 선택한 특성의 이름 - dependence plot 이용하기 위한 역변환 과정\n",
    "    for selected_feature_name in X_test.columns:\n",
    "        print(selected_feature_name)\n",
    "        selected_feature_index = df.columns.get_loc(selected_feature_name) - 5\n",
    "\n",
    "        # RobustScaler의 중앙값과 IQR 이용\n",
    "        center = scaler.center_[selected_feature_index]\n",
    "        scale = scaler.scale_[selected_feature_index]\n",
    "\n",
    "        # 스케일링된 데이터를 원래 값으로 역변환\n",
    "        feature_values_original = X_test[selected_feature_name].values * scale + center\n",
    "\n",
    "        # dependence plot 그리기\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        plt.scatter(feature_values_original, shap_values[:, selected_feature_index], c=y_test)\n",
    "        plt.xlabel(selected_feature_name)\n",
    "        plt.ylabel('SHAP Value')\n",
    "        plt.title(f'GRU B with SHAP - Dependence Plot for {selected_feature_name}')\n",
    "        plt.colorbar(label='Actual Target Value')\n",
    "        plt.savefig(f\"{selected_feature_name}_dependence_plot_original.png\")\n",
    "        plt.show()\n",
    "\n",
    "    # feature importance plot 그리기\n",
    "    shap_values = explainer(X_test)\n",
    "    shap.plots.bar(shap_values)\n",
    "\n",
    "    return models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
